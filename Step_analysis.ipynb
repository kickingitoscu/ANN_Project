{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rodolfocacacho/Documents/Documents/MAI/1.Semester/Artificial Neural Networks and Cognitive Models/Kaggle competition dataset/ANN_Project/data/\n",
      "['person_8', 'person_7', 'person_12', 'person_5', 'person_2', 'person_3', 'person_4', 'person_11', 'person_10']\n"
     ]
    }
   ],
   "source": [
    "def get_subdirectories(folder_path):\n",
    "    subdirectories = []\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "    return subdirectories\n",
    "\n",
    "def get_files_in_subdirectories(folder_path, file_extension='', file_contains=''):\n",
    "    files = []\n",
    "    for root, directories, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if file_extension == '' and file_contains == '':\n",
    "                files.append(os.path.join(root, filename))\n",
    "            elif file_extension != '' and file_contains == '':\n",
    "                if filename.endswith(file_extension):\n",
    "                    files.append(os.path.join(root, filename))\n",
    "            elif file_extension == '' and file_contains != '':\n",
    "                if file_contains in filename:\n",
    "                    files.append(os.path.join(root, filename))\n",
    "            else:\n",
    "                if file_contains in filename and filename.endswith(file_extension):\n",
    "                    files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "def get_num(text):\n",
    "    if isinstance(text, list):\n",
    "        numbers = []\n",
    "        for item in text:\n",
    "            number_str = search(r'\\d+(?=[^\\d]*\\.csv)', str(item))[0]\n",
    "            if number_str:\n",
    "                numbers.append(number_str)\n",
    "        return numbers\n",
    "    else:\n",
    "        number_str = search(r'\\d+(?=[^\\d]*\\.csv)', str(text))[0]\n",
    "        return number_str if number_str else None\n",
    "\n",
    "# def read_csv_to_tensor(file_path, tensor_name):\n",
    "#     # Read CSV file as a pandas DataFrame\n",
    "#     dataframe = pd.read_csv(file_path)\n",
    "#     # Convert DataFrame to a tensor\n",
    "#     tensor = torch.tensor(dataframe.values)\n",
    "#     # Assign the tensor to the specified variable name\n",
    "#     locals()[tensor_name] = tensor\n",
    "\n",
    "def read_csv_to_tensor(file_path, tensor_name, tensors_dict):\n",
    "    # Read CSV file as a pandas DataFrame\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert DataFrame to a tensor\n",
    "    tensor = torch.tensor(dataframe.values)\n",
    "\n",
    "    # Store the tensor in the dictionary with the specified variable name\n",
    "    tensors_dict[tensor_name] = tensor\n",
    "\n",
    "def read_csv_to_tensor2(file_path):#, tensor_name, tensors_dict):\n",
    "    # Read CSV file as a pandas DataFrame\n",
    "    return pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert DataFrame to a tensor\n",
    "    #tensor = torch.tensor(dataframe.values)\n",
    "\n",
    "    # Store the tensor in the dictionary with the specified variable name\n",
    "    #tensors_dict[tensor_name] = tensor\n",
    "\n",
    "\n",
    "# main_df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "# index_label_df = pd.DataFrame({'index': [0, 2], 'label': ['Label1', 'Label2']})\n",
    "\n",
    "# merged_df = pd.merge(main_df, index_label_df, left_index=True, right_on='index', how='left')\n",
    "# final_df = merged_df.drop(['index', 'label'], axis=1).set_index('label')\n",
    "\n",
    "\n",
    "folder_path = os.getcwd()+'/data/'\n",
    "print(folder_path)\n",
    "subdirectories = get_subdirectories(folder_path)\n",
    "print(subdirectories)\n",
    "\n",
    "file_extension = ['.csv','.csv.stepMixed']\n",
    "label = ['data','labels']\n",
    "tensors = {}\n",
    "\n",
    "for i in subdirectories:\n",
    "    folder_i = folder_path+i\n",
    "    files_t = get_files_in_subdirectories(folder_i)\n",
    "    files_n = list(dict.fromkeys(get_num(files_t)))\n",
    "    for index_j,j in enumerate(files_n):\n",
    "        name_variable = i+'_'+str(index_j)\n",
    "        for index_k,k in enumerate(file_extension):\n",
    "            files = get_files_in_subdirectories(folder_i,file_extension=k,file_contains=j)\n",
    "            name_variableR = i+'_'+j+'_'+label[index_k]\n",
    "            # print(f'variable: {name_variableR} person: {i} file_extension: {k} file_path: {files}')\n",
    "            if index_k == 0:\n",
    "                main_df = read_csv_to_tensor2(files[0])#,name_variable,tensors)\n",
    "            else:\n",
    "                label_df = pd.read_csv(files[0],names = ['start','end'])\n",
    "                index_start = label_df.start.tolist()\n",
    "                index_end = label_df.end.tolist()\n",
    "        # Add a new column with a specific value for the matching row indexes\n",
    "        main_df['label1'] = main_df.apply(lambda row: 'start' if row.name in index_start else '', axis=1)\n",
    "        main_df['label2'] = main_df.apply(lambda row: 'end' if row.name in index_end else '', axis=1)\n",
    "        # Define the condition for the new column\n",
    "        condition1 = main_df['label1'] == 'start'\n",
    "        condition2 = main_df['label2'] == 'end'\n",
    "        # Assign values based on the condition using np.where()\n",
    "        main_df['label'] = np.where(condition1,1,\n",
    "                                np.where(condition2,2,0))\n",
    "        main_df = main_df.drop(['label1', 'label2'], axis=1)\n",
    "        # print(main_df)\n",
    "        # Convert DataFrame to a tensor\n",
    "        tensor = torch.tensor(main_df.values)\n",
    "        # Store the tensor in the dictionary with the specified variable name\n",
    "        tensors[name_variable] = tensor\n",
    "\n",
    "# Labels are:\n",
    "# 0 - Neither start nor end\n",
    "# 1 - Start\n",
    "# 2 - End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -2.6150,  5.3916,  ...,  0.0148,  0.0101,  0.0000],\n",
       "        [ 0.0000, -2.5290,  5.3612,  ...,  0.0143,  0.0200,  0.0000],\n",
       "        [ 0.0000, -2.5290,  5.3612,  ...,  0.0143,  0.0200,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000, -0.4884,  5.8274,  ..., -0.3436, -0.2903,  0.0000],\n",
       "        [ 0.0000, -0.5159,  5.8757,  ..., -0.3344, -0.2963,  0.0000],\n",
       "        [ 0.0000, -0.5594,  5.8534,  ..., -0.3134, -0.3382,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors['person_10_0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env_ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
